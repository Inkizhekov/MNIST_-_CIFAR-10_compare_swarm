{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization of Neural Network Hyperparameters using PSO and Grid Search\n",
    "\n",
    "In this notebook, we compare Particle Swarm Optimization (PSO) with Grid Search for optimizing the hyperparameters and architecture of a neural network using a subset of the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import psutil  # For monitoring memory usage\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from pyswarm import pso\n",
    "\n",
    "# Define maximum available memory in bytes\n",
    "max_memory_bytes = psutil.virtual_memory().available\n",
    "\n",
    "# Set maximum data size\n",
    "max_train_samples = 2000\n",
    "max_test_samples = 500\n",
    "\n",
    "# Load CIFAR-10 data\n",
    "(x_train_full, y_train_full), (x_test_full, y_test_full) = cifar10.load_data()\n",
    "\n",
    "# Use only a portion of the data for acceleration and reduced memory consumption\n",
    "x_train = x_train_full[:max_train_samples]\n",
    "y_train = y_train_full[:max_train_samples]\n",
    "x_test = x_test_full[:max_test_samples]\n",
    "y_test = y_test_full[:max_test_samples]\n",
    "\n",
    "# Normalize data\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a model\n",
    "def create_model(num_neurons, learning_rate, dropout_rate, l2_rate, num_layers):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(32, 32, 3)))\n",
    "    for _ in range(int(num_layers)):\n",
    "        model.add(Dense(int(num_neurons), activation='relu', kernel_regularizer=l2(l2_rate)))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(num_neurons, learning_rate, dropout_rate, l2_rate, num_layers):\n",
    "    model = create_model(num_neurons, learning_rate, dropout_rate, l2_rate, num_layers)\n",
    "    history = model.fit(x_train, y_train, epochs=1, batch_size=32, verbose=0, validation_data=(x_test, y_test))\n",
    "    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    tf.keras.backend.clear_session()  # Ensure to clear session properly\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Grid Search considering memory constraint\n",
    "def grid_search(params_grid):\n",
    "    best_params = None\n",
    "    best_accuracy = 0.0\n",
    "    for params in ParameterGrid(params_grid):\n",
    "        memory_estimate = params['num_neurons'] * params['num_layers'] * 4 * max_train_samples\n",
    "        if memory_estimate > max_memory_bytes:\n",
    "            continue  # Skip parameters if exceeding available memory\n",
    "        accuracy = evaluate_model(params['num_neurons'], params['learning_rate'], params['dropout_rate'], params['l2_rate'], params['num_layers'])\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = params\n",
    "    return best_params, best_accuracy\n",
    "\n",
    "# Function for PSO\n",
    "def pso_objective(params):\n",
    "    num_neurons, learning_rate, dropout_rate, l2_rate, num_layers = params\n",
    "    memory_estimate = num_neurons * num_layers * 4 * max_train_samples\n",
    "    if memory_estimate > max_memory_bytes:\n",
    "        return -1  # Return negative value if exceeding available memory\n",
    "    accuracy = evaluate_model(num_neurons, learning_rate, dropout_rate, l2_rate, num_layers)\n",
    "    return -accuracy  # PSO minimizes the objective function, so use negative accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for Grid Search\n",
    "params_grid = {\n",
    "    'num_neurons': [64, 128, 256],\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'dropout_rate': [0.2, 0.4, 0.6],\n",
    "    'l2_rate': [0.01, 0.001],\n",
    "    'num_layers': [1, 2, 3]\n",
    "}\n",
    "\n",
    "# Run Grid Search\n",
    "start_time = time.time()\n",
    "best_params_grid, best_accuracy_grid = grid_search(params_grid)\n",
    "grid_search_time = time.time() - start_time\n",
    "print(f\"Grid Search took {grid_search_time:.3f} seconds.\")\n",
    "print(f\"Best parameters: {best_params_grid}\")\n",
    "print(f\"Best accuracy: {best_accuracy_grid:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the lower and upper bounds for PSO\n",
    "lb = [64, 0.001, 0.2, 0.001, 1]  # Lower bounds\n",
    "ub = [256, 0.1, 0.6, 0.01, 3]   # Upper bounds\n",
    "\n",
    "# Run PSO\n",
    "start_time = time.time()\n",
    "best_params_pso, best_score_pso = pso(pso_objective, lb, ub, swarmsize=10, maxiter=5)\n",
    "pso_time = time.time() - start_time\n",
    "print(f\"PSO took {pso_time:.3f} seconds.\")\n",
    "print(f\"Best parameters: {best_params_pso}\")\n",
    "print(f\"Best accuracy: {-best_score_pso:.4f}\")  # Convert back to positive accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of results\n",
    "labels = ['Grid Search', 'PSO']\n",
    "accuracies = [best_accuracy_grid, -best_score_pso]  # Convert PSO score to positive\n",
    "times = [grid_search_time, pso_time]\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Method')\n",
    "ax1.set_ylabel('Accuracy', color=color)\n",
    "ax1.bar(labels, accuracies, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Time (s)', color=color)\n",
    "ax2.plot(labels, times, color=color, marker='o')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title('Comparison of Grid Search and PSO')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
